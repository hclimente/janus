{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "from socket import gethostname\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "from janus.datasets import Boyd2019\n",
    "from janus.losses import ContrastiveLoss\n",
    "from janus.networks import SiameseNet\n",
    "from src.viz import plot_cell, tsne, umap\n",
    "\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device)\n",
    "\n",
    "data_path = '../data/boyd_2019'\n",
    "results_path = '../results/boyd_2019'\n",
    "metadata_file = '../data/boyd_2019_PlateMap-KPP_MOA.xlsx'\n",
    "\n",
    "metadata = Boyd2019.read_metadata(metadata_file)\n",
    "\n",
    "# filter by 2 moas and make train test\n",
    "metadata = metadata.loc[metadata.moa.isin(['Neutral', 'EGF Receptor Kinase Inhibitor'])]\n",
    "train_metadata = metadata.sample(frac=0.7)\n",
    "test_metadata = metadata.drop(train_metadata.index)\n",
    "\n",
    "boyd2019 = Boyd2019(data_path, train_metadata, padding=64, scale=0.5)\n",
    "\n",
    "for i in np.random.randint(1, 1000, 4):\n",
    "    plot_cell(boyd2019.dataset_1[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boyd2019.metadata.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Dataset 1: %d cells' % len(boyd2019.dataset_1))\n",
    "print('Dataset 2: %d cells' % len(boyd2019.dataset_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def imshow(img, text=None, should_save=False):\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(15, 5))\n",
    "\n",
    "    npimg = img.numpy()\n",
    "\n",
    "    if text:\n",
    "        plt.text(75, 8, text, style='italic',fontweight='bold',\n",
    "            bbox={'facecolor':'white', 'alpha':0.8, 'pad':10})\n",
    "\n",
    "    ax.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    ax.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def show_plot(iteration,loss):\n",
    "    plt.plot(iteration,loss)\n",
    "    plt.show()\n",
    "\n",
    "vis_dataloader = DataLoader(boyd2019,\n",
    "                            shuffle=True,\n",
    "                            num_workers=8,\n",
    "                            batch_size=8)\n",
    "dataiter = iter(vis_dataloader)\n",
    "\n",
    "example_batch = next(dataiter)\n",
    "concatenated = torch.cat((example_batch[0], example_batch[2]),0)\n",
    "print(example_batch[4].numpy())\n",
    "imshow(torchvision.utils.make_grid(concatenated))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load saved net\n",
    "model = 'sn_dropout_0.5_margin_1.0_seed_5_epoch_100.torch'\n",
    "\n",
    "net = SiameseNet().to(device)\n",
    "net.load_state_dict(torch.load(join(results_path, model),\n",
    "                               map_location=torch.device(device)))\n",
    "net = net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get test set: different wells than training\n",
    "# test_metadata = pd.DataFrame({'well': ['C01', 'D02'], 'moa': [1, 2]})\n",
    "test_boyd2019 = Boyd2019(data_path, test_metadata, padding=64, scale=0.5)\n",
    "\n",
    "test_dataloader = DataLoader(test_boyd2019,\n",
    "                             shuffle=True,\n",
    "                             num_workers=8,\n",
    "                             batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from src.viz import norm_crop_for_vis\n",
    "\n",
    "# sample test set\n",
    "embedding = np.empty((0, 256))\n",
    "moas = []\n",
    "cell_line = np.empty((0,))\n",
    "\n",
    "all_imgs = []\n",
    "\n",
    "for i, data in enumerate(test_dataloader, 0):\n",
    "    img0, moa0, img1, moa1, _ = data\n",
    "    img0, img1 = img0.to(device), img1.to(device)\n",
    "    output1, output2 = net(img0, img1)\n",
    "\n",
    "    embedding = np.concatenate((embedding, output1.detach().numpy(), output2.detach().numpy()))\n",
    "    cell_line = np.concatenate((cell_line,\n",
    "                                np.repeat('mda468', output1.shape[0]),\n",
    "                                np.repeat('mda231', output2.shape[0])))\n",
    "    moas.extend(moa0)\n",
    "    moas.extend(moa1)\n",
    "\n",
    "    normed_img0 = torch.cat([norm_crop_for_vis(img)[None] for img in img0], axis=0)\n",
    "    normed_img1 = torch.cat([norm_crop_for_vis(img)[None] for img in img1], axis=0)\n",
    "\n",
    "    all_imgs.append(normed_img0)\n",
    "    all_imgs.append(normed_img1)\n",
    "\n",
    "    if i == 100:\n",
    "        break\n",
    "\n",
    "all_imgs = torch.cat(all_imgs).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from umap import UMAP\n",
    "from src.viz import xy_plot\n",
    "\n",
    "x_emb = UMAP().fit_transform(embedding)\n",
    "xy_plot(x_emb, cell_line, 'UMAP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from src.viz import plot_tiles\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "canvas, img_idx_dict = plot_tiles(all_imgs, x_emb, 30, pad=1)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 15))\n",
    "ax.imshow(canvas)\n",
    "ax.axis('off')\n",
    "\n",
    "palette = list(sns.color_palette().as_hex())\n",
    "\n",
    "# for img_key in img_idx_dict.keys():\n",
    "#     xmin, xmax, ymin, ymax = img_idx_dict[img_key]\n",
    "#     cls = moas[img_key].item()\n",
    "#     colour = palette[0] if cls == 1 else palette[1]\n",
    "#     # Create a Rectangle patch\n",
    "#     line_width = 3\n",
    "#     rect = patches.Rectangle((xmin+line_width, ymin+line_width), xmax-xmin-2*line_width, ymax-ymin-2*line_width,\n",
    "#                              linewidth=line_width, edgecolor=colour, facecolor='none')\n",
    "#     # Add the patch to the Axes\n",
    "#     ax.add_patch(rect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "umap(embedding, moas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MoA Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from src.lococv import LocoCV\n",
    "from src.viz import plot_confusion_matrix\n",
    "\n",
    "loco = LocoCV(test_boyd2019, net)\n",
    "\n",
    "df_profiles = loco.construct_profiles()\n",
    "confusion = loco.lococv(df_profiles)\n",
    "\n",
    "ae_acc = np.trace(confusion) / np.sum(confusion)\n",
    "print('Accuracy: %.04f' % ae_acc)\n",
    "\n",
    "plot_confusion_matrix(confusion, test_boyd2019.metadata.moa.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
